


# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "data/Mouse_metadata.csv"
study_results_path = "data/Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single DataFrame
print(mouse_metadata.columns)
print(study_results.columns)
merged = pd.merge(mouse_metadata, study_results, how="right", on='Mouse ID')

# Display the data table for preview
merged.head()




# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "data/Mouse_metadata.csv"
study_results_path = "data/Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single DataFrame


# Display the data table for preview



# Checking the number of mice.
mice_count = mouse_metadata['Mouse ID'].count()
mice_count


# Our data should be uniquely identified by Mouse ID and Timepoint
# Get the duplicate mice by ID number that shows up for Mouse ID and Timepoint. 

# duplicate_mice = merged[merged.duplicated(subset=['Mouse ID', 'Timepoint'], keep=False)]
duplicate_mice = merged[merged.duplicated(subset=['Mouse ID', 'Timepoint'], keep=False)]['Mouse ID'].unique()
print(duplicate_mice)


# Optional: Get all the data for the duplicate mouse ID. 
duplicate_mouse_data = merged[merged['Mouse ID'] == 'g989']

duplicate_mouse_data



# Create a clean DataFrame by dropping the duplicate mouse by its ID.
cleaned_data = merged[merged['Mouse ID'] != 'g989']
cleaned_data.head()



# Checking the number of mice in the clean DataFrame.
mice_count_cleaned = cleaned_data['Mouse ID'].nunique()
mice_count_cleaned





# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 

Tumor_volume_mean = cleaned_data.groupby(['Drug Regimen'])['Tumor Volume (mm3)'].mean()
Tumor_volume_mean 
Tumor_volume_median = cleaned_data.groupby(['Drug Regimen'])['Tumor Volume (mm3)'].median()
Tumor_volume_median
Tumor_volume_variance = cleaned_data.groupby(['Drug Regimen'])['Tumor Volume (mm3)'].var()
Tumor_volume_variance
Tumor_volume_Std_Dev = cleaned_data.groupby(['Drug Regimen'])['Tumor Volume (mm3)'].std()
Tumor_volume_Std_Dev

# Calculate the number of samples in each group
sample_sizes = cleaned_data.groupby('Drug Regimen')['Tumor Volume (mm3)'].count()

# Calculate the SEM using the formula: SEM = standard deviation / sqrt(sample size)
SEM = Tumor_volume_Std_Dev / np.sqrt(sample_sizes)
SEM

# Assemble the resulting series into a single summary DataFrame.

Drug_Regimen_df = pd.DataFrame({'Mean Tumor Volume': Tumor_volume_mean, 
                                'Median Tumor Volume': Tumor_volume_median, 
                                'Tumor Volume Variance': Tumor_volume_variance, 
                                'Tumor Volume Std. Dev.': Tumor_volume_Std_Dev,
                                'Tumor Volume Std. Err.': SEM})
Drug_Regimen_df


# A more advanced method to generate a summary statistics table of mean, median, variance, standard deviation,
# and SEM of the tumor volume for each regimen (only one method is required in the solution)

summary_table = cleaned_data.groupby("Drug Regimen").agg({"Tumor Volume (mm3)" : ["mean","median","var","std","sem"]})
summary_table
# Using the aggregation method, produce the same summary statistics in a single line





# Generate a bar plot showing the total number of rows (Mouse ID/Timepoints) for each drug regimen using Pandas.
count = cleaned_data['Drug Regimen'].value_counts()
count.plot(kind='bar')
plt.xlabel('Drug Regimen')
plt.xticks(rotation= 90)
plt.ylabel('Number of observed mice/ Timepoints')
plt.show()



# Generate a bar plot showing the total number of rows (Mouse ID/Timepoints) for each drug regimen using pyplot.
count = cleaned_data['Drug Regimen'].value_counts()
plt.bar(count.index.values,count.values)
plt.xlabel('Drug Regimen')
plt.xticks(rotation= 90)
plt.ylabel('Number of observed mice/ Timepoints')
plt.show()


# Generate a pie plot showing the distribution of female versus male mice using Pandas
count = cleaned_data['Sex'].value_counts()
count.plot(kind='pie', autopct= '%1.1f%%')
plt.ylabel('Sex')
plt.show()



# Generate a pie plot showing the distribution of female versus male mice using pyplot
count = cleaned_data['Sex'].value_counts()
plt.pie(count.values, labels= count.index.values, autopct= '%1.1f%%')
# plt.bar(count.index.values,count.values)
plt.ylabel('Sex')
plt.show()





# Calculate the final tumor volume of each mouse across four of the treatment regimens:  
# Capomulin, Ramicane, Infubinol, and Ceftamin

# Start by getting the last (greatest) timepoint for each mouse


# Merge this group df with the original DataFrame to get the tumor volume at the last timepoint



# Put treatments into a list for for loop (and later for plot labels)


# Create empty list to fill with tumor vol data (for plotting)


# Calculate the IQR and quantitatively determine if there are any potential outliers. 

    
    # Locate the rows which contain mice on each drug and get the tumor volumes

    
    # add subset 

    
    # Determine outliers using upper and lower bounds



# Generate a box plot that shows the distrubution of the tumor volume for each treatment group.






# Generate a line plot of tumor volume vs. time point for a single mouse treated with Capomulin



# Generate a scatter plot of mouse weight vs. the average observed tumor volume for the entire Capomulin regimen






# Calculate the correlation coefficient and a linear regression model 
# for mouse weight and average observed tumor volume for the entire Capomulin regimen




